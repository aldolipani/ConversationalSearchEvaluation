{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import get_session_ids, get_all_sequences, get_topics, get_sub_topics, product,to_matrix\n",
    "from search_engine import *\n",
    "from numpy.random import choice\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "path_log = './data/log.2.tsv'\n",
    "path_topic = './data/topic.tsv'\n",
    "path_sub_topic = './data/sub_topic.tsv'\n",
    "path_retrievable_paragraph = './data/retrievable_paragraph.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "session_ids = get_session_ids(path_log)\n",
    "all_sequences = get_all_sequences(path_log, session_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "topics = get_topics(path_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# topic -> sub_topic -> queries\n",
    "all_queries = {}\n",
    "\n",
    "for topic in all_sequences:\n",
    "    \n",
    "    queries = defaultdict(list)\n",
    "    for sequence in all_sequences[topic]:\n",
    "        for action in sequence:\n",
    "            sub_topic = action[3]\n",
    "            query = action[4]\n",
    "            queries[sub_topic].append(query)\n",
    "    \n",
    "    all_queries[topic] = queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# topic -> sub_topic -> paragraphs\n",
    "qrels = defaultdict(dict)\n",
    "\n",
    "sub_topic_to_paragraph = defaultdict(set)\n",
    "with open(path_retrievable_paragraph) as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        items = line.split('\\t')\n",
    "        sub_topic = int(items[0])\n",
    "        paragraph = int(items[1])\n",
    "        sub_topic_to_paragraph[sub_topic].add(paragraph)\n",
    "\n",
    "sub_topics = get_sub_topics(path_sub_topic)\n",
    "\n",
    "for topic in sub_topics:\n",
    "    for sub_topic in sub_topics[topic]:\n",
    "        qrels[topic][sub_topic] = sub_topic_to_paragraph[sub_topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{10: {2: {371: 0.95},\n  3: {380: 0.7222222222222222, 381: 0.7, 379: 1.0},\n  1: {374: 0.8333333333333334, 372: 1.0},\n  4: {386: 0.6551724137931034, 385: 1.0},\n  5: {371: 0.5714285714285714}},\n 5: {10: {511: 0.9444444444444444},\n  9: {521: 0.8235294117647058, 504: 0.6666666666666666, 502: 1.0},\n  8: {501: 0.8},\n  6: {496: 0.03125},\n  7: {521: 0.42105263157894735, 499: 0.3333333333333333},\n  11: {499: 0.26666666666666666, 521: 0.6666666666666666}},\n 6: {13: {689: 1.0, 675: 0.8},\n  14: {675: 0.42857142857142855, 699: 1.0},\n  15: {699: 0.75, 708: 1.0},\n  17: {708: 1.0, 675: 0.4},\n  12: {699: 0.5, 689: 1.0},\n  16: {675: 0.9230769230769231, 674: 1.0}},\n 4: {20: {597: 0.5882352941176471},\n  22: {600: 0.6538461538461539},\n  18: {607: 0.8421052631578947},\n  26: {602: 0.26666666666666666},\n  19: {597: 0.2631578947368421},\n  25: {596: 1.0, 619: 1.0},\n  27: {602: 1.0},\n  21: {596: 1.0},\n  24: {600: 0.0},\n  23: {607: 1.0}},\n 2: {28: {474: 0.9583333333333334, 475: 0.6666666666666666},\n  29: {474: 0.8333333333333334, 491: 1.0, 475: 1.0, 477: 1.0},\n  31: {474: 0.8571428571428571, 495: 1.0},\n  30: {483: 0.7297297297297297},\n  32: {487: 0.9259259259259259, 480: 1.0, 475: 0.0}},\n 9: {34: {1: 1.0},\n  35: {2: 0.9375},\n  36: {1: 0.5555555555555556, 2: 0.46153846153846156},\n  33: {8: 1.0, 19: 0.4166666666666667, 17: 1.0}},\n 1: {39: {644: 0.7692307692307693, 622: 0.75, 639: 0.0},\n  38: {636: 0.8571428571428571, 624: 0.0},\n  40: {623: 1.0},\n  41: {632: 0.5454545454545454, 622: 1.0},\n  37: {632: 0.8888888888888888, 623: 1.0}},\n 8: {50: {282: 0.8888888888888888, 264: 1.0},\n  49: {294: 0.11764705882352941},\n  45: {294: 1.0},\n  46: {301: 1.0},\n  44: {286: 0.5217391304347826},\n  48: {286: 0.3125},\n  47: {301: 0.3333333333333333},\n  43: {286: 0.3333333333333333, 264: 1.0},\n  42: {283: 1.0}},\n 11: {51: {331: 0.6666666666666666},\n  54: {332: 0.75, 331: 1.0},\n  56: {353: 0.5, 334: 1.0},\n  58: {353: 0.5},\n  52: {332: 0.8333333333333334},\n  55: {333: 1.0, 332: 1.0},\n  60: {337: 1.0},\n  53: {331: 1.0},\n  57: {336: 1.0},\n  59: {353: 1.0}},\n 7: {61: {801: 0.8888888888888888},\n  62: {801: 0.8571428571428571},\n  63: {829: 0.9166666666666666, 813: 0.6, 810: 0.0},\n  64: {831: 1.0},\n  65: {838: 0.9230769230769231, 828: 0.0},\n  66: {803: 1.0, 833: 1.0}},\n 3: {69: {860: 0.88},\n  67: {850: 0.9333333333333333, 852: 0.875, 860: 0.0},\n  68: {852: 1.0},\n  70: {853: 1.0},\n  71: {859: 1.0, 855: 0.0},\n  72: {850: 0.9166666666666666}}}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "# from users continuos\n",
    "# topic -> sub_topic -> paragraphs\n",
    "qrels_users = {}\n",
    "\n",
    "for topic in sub_topics:\n",
    "    for sequence in all_sequences[topic]:\n",
    "        for action in sequence:\n",
    "            paragraph = action[1]\n",
    "            rel = action[2]\n",
    "            sub_topic = action[3]\n",
    "            if topic not in qrels_users:\n",
    "                qrels_users[topic] = {}\n",
    "            if sub_topic not in qrels_users[topic]:\n",
    "                qrels_users[topic][sub_topic] = {}\n",
    "            if paragraph not in qrels_users[topic][sub_topic]:\n",
    "                qrels_users[topic][sub_topic][paragraph] = (0, 0)\n",
    "            num, den = qrels_users[topic][sub_topic][paragraph]\n",
    "            if rel == 'relevant':\n",
    "                qrels_users[topic][sub_topic][paragraph] = (num + 1, den + 1)\n",
    "            else:\n",
    "                qrels_users[topic][sub_topic][paragraph] = (num, den + 1)\n",
    "\n",
    "for topic in qrels_users:\n",
    "    for sub_topic in qrels_users[topic]:\n",
    "        for paragraph in qrels_users[topic][sub_topic]:\n",
    "            num, den = qrels_users[topic][sub_topic][paragraph]\n",
    "            qrels_users[topic][sub_topic][paragraph] = num/den\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Search System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "direct_index = DirectIndex.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pre_preocessor = PreProcessor()\n",
    "\n",
    "def select_random_documents(documents:set, p:float=0.0):\n",
    "    assert(0.0 <= p <= 1.0)\n",
    "    if p == 0.0:\n",
    "        return set()\n",
    "    elif p == 1.0:\n",
    "        return documents\n",
    "    else:\n",
    "        return set(choice(list(documents), replace=False, size = int(len(documents) * p)))\n",
    "        \n",
    "def get_search_engine(topic, sub_topic, qrels, direct_index, noise = 0.0):\n",
    "    # select documents belonging to the topic\n",
    "    selected_documents = {}\n",
    "    for document in qrels[topic][sub_topic]:\n",
    "        selected_documents[document] = direct_index.index[document]\n",
    "        \n",
    "    # select random documents\n",
    "    # 1. from topic documents\n",
    "    topic_documents = set()\n",
    "    for _, sub_topic_documents in qrels[topic].items():\n",
    "        topic_documents.update(sub_topic_documents)    \n",
    "    topic_documents = select_random_documents(topic_documents, noise)\n",
    "    \n",
    "    for document in topic_documents:\n",
    "        selected_documents[document] = direct_index.index[document]\n",
    "    \n",
    "    # 2. from all_documents\n",
    "    all_documents = direct_index.index.keys()\n",
    "    all_documents = select_random_documents(all_documents, noise)\n",
    "\n",
    "    for document in all_documents:\n",
    "        selected_documents[document] = direct_index.index[document]\n",
    "        \n",
    "    # retrievable documents\n",
    "    inverted_index = InvertedIndex()\n",
    "    inverted_index.create(selected_documents)\n",
    "        \n",
    "    return selected_documents, inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_transitions_tables(num_subtopics, min_sub_topic, sequences, epsilon = 0.0):\n",
    "    rel_transitions_table = defaultdict(float)\n",
    "    irr_transitions_table = defaultdict(float)\n",
    "    p_rel = defaultdict(float)\n",
    "    p_irr = defaultdict(float)\n",
    "    for sequence in sequences:\n",
    "        last_key = None\n",
    "        last_rel = 'irrelevant'\n",
    "        for n, action in enumerate(sequence):\n",
    "            if n == 0:\n",
    "                key = (action[0], action[3] - min_sub_topic + 1)\n",
    "            else:\n",
    "                key = (action[0] - min_sub_topic + 1, action[3] - min_sub_topic + 1)\n",
    "            if last_rel == 'relevant':\n",
    "                rel_transitions_table[key] += 1\n",
    "                p_rel[key[0]] += 1\n",
    "            else:\n",
    "                irr_transitions_table[key] += 1\n",
    "                p_irr[key[0]] += 1\n",
    "            last_key = key\n",
    "            last_rel = action[2]\n",
    "        \n",
    "        if last_rel == 'relevant':\n",
    "            rel_transitions_table[(last_key[1], num_subtopics+1)] += 1\n",
    "            p_rel[last_key[1]] += 1\n",
    "        else:\n",
    "            irr_transitions_table[(last_key[1], num_subtopics+1)] += 1\n",
    "            p_irr[last_key[1]] += 1\n",
    "        \n",
    "    rel_norms = defaultdict(float)\n",
    "    for from_subtopic, to_subtopic in product(range(num_subtopics+1), range(1, num_subtopics+2)):\n",
    "        if from_subtopic > 0:            \n",
    "            rel_transitions_table[(from_subtopic, to_subtopic)] += epsilon\n",
    "        rel_norms[from_subtopic] += rel_transitions_table[(from_subtopic, to_subtopic)]\n",
    "    \n",
    "    irr_norms = defaultdict(float)\n",
    "    for from_subtopic, to_subtopic in product(range(num_subtopics+1), range(1, num_subtopics+2)):\n",
    "        if not (from_subtopic == 0 and to_subtopic == num_subtopics + 1):\n",
    "            irr_transitions_table[(from_subtopic, to_subtopic)] += epsilon\n",
    "        irr_norms[from_subtopic] += irr_transitions_table[(from_subtopic, to_subtopic)]\n",
    "    \n",
    "    for from_subtopic, to_subtopic in product(range(num_subtopics+1), range(1, num_subtopics+2)):\n",
    "        if rel_norms[from_subtopic] > 0.0:\n",
    "            rel_transitions_table[(from_subtopic, to_subtopic)] /= (rel_norms[from_subtopic]) \n",
    "    \n",
    "    for from_subtopic, to_subtopic in product(range(num_subtopics+1), range(1, num_subtopics+2)):\n",
    "        if irr_norms[from_subtopic] > 0.0:\n",
    "            irr_transitions_table[(from_subtopic, to_subtopic)] /= (irr_norms[from_subtopic])\n",
    "    \n",
    "    p = []\n",
    "    for t in range(num_subtopics + 1):\n",
    "        if (p_rel[t] + p_irr[t]) > 0:\n",
    "            p.append(p_rel[t]/(p_rel[t] + p_irr[t]))\n",
    "        else:\n",
    "            p.append(0.0)\n",
    "    p = np.array([p])\n",
    "\n",
    "    return rel_transitions_table, irr_transitions_table, p, 1 - p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class SequenceGenerator:\n",
    "    \n",
    "    def __init__(self, num_subtopics, min_sub_topic, rel_table, irr_table):\n",
    "        self.num_subtopics = num_subtopics\n",
    "        self.rel_table = to_matrix(rel_table)\n",
    "        self.irr_table = to_matrix(irr_table)\n",
    "        self.min_sub_topic = min_sub_topic\n",
    "        self.relevance = False\n",
    "        self.current_subtopic = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        #self.current_subtopic = 0\n",
    "        return self\n",
    "    \n",
    "    def set_relevance(self, relevance):\n",
    "        self.relevance = relevance\n",
    "    \n",
    "    def __next__(self):\n",
    "        next_subtopic = -1\n",
    "        prob = -1\n",
    "        if self.current_subtopic + self.min_sub_topic - 1 == self.num_subtopics + 1 + self.min_sub_topic - 1:\n",
    "            raise StopIteration\n",
    "        if self.relevance:\n",
    "            #print(self.rel_table[self.current_subtopic].sum())\n",
    "            next_subtopic = choice(range(1, self.num_subtopics + 2), \n",
    "                                   1, \n",
    "                                   p=self.rel_table[self.current_subtopic])[0]\n",
    "            prob = self.rel_table[self.current_subtopic, next_subtopic - 1]\n",
    "        else:\n",
    "            #print(self.irr_table[self.current_subtopic].sum())\n",
    "            next_subtopic = choice(range(1, self.num_subtopics + 2), \n",
    "                                   1, \n",
    "                                   p=self.irr_table[self.current_subtopic])[0]\n",
    "            prob = self.irr_table[self.current_subtopic, next_subtopic - 1]\n",
    "        self.current_subtopic = next_subtopic\n",
    "        return next_subtopic + self.min_sub_topic - 1, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis with Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# CP\n",
    "\n",
    "def dd_cp(alpha, m, l):\n",
    "    return 1\n",
    "\n",
    "def ncp(sequence):\n",
    "    res = 0.0\n",
    "    for action in sequence:\n",
    "        if action[2] == 'relevant':\n",
    "            res += dd_cp(None, None, None)\n",
    "    return res/len(sequence)\n",
    "\n",
    "# CBP\n",
    "\n",
    "def dd_cbp(alpha, m, l = None):\n",
    "    return alpha ** m\n",
    "\n",
    "def dd_ncbp(alpha, m, l):\n",
    "    return dd_cbp(alpha, m, l)\n",
    "\n",
    "def ncbp(sequence, alpha):\n",
    "    norm = 0.0\n",
    "    for i in range(len(sequence)):\n",
    "        norm += dd_cbp(alpha, i, len(sequence))\n",
    "    res = 0.0\n",
    "    for m, action in enumerate(sequence):\n",
    "        if action[2] == 'relevant':\n",
    "            res += dd_ncbp(alpha, m, len(sequence))\n",
    "    return res/norm\n",
    "\n",
    "# ECS\n",
    "\n",
    "def dd_necs(alpha_rel, alpha_irr, m, sequence):\n",
    "    res = 1.0\n",
    "    for action in sequence[:m]:\n",
    "        if action[2] == 'relevant':\n",
    "            res *= alpha_rel\n",
    "        else:\n",
    "            res *= alpha_irr\n",
    "    return res\n",
    "\n",
    "def necs(sequence, alpha_rel, alpha_irr):\n",
    "    norm = 0.0\n",
    "    for i in range(len(sequence)):\n",
    "        norm += dd_cbp(alpha_rel, i)\n",
    "    res = 0.0\n",
    "    for m, action in enumerate(sequence):\n",
    "        if action[2] == 'relevant':\n",
    "            res += dd_necs(alpha_rel, alpha_irr, m, sequence)\n",
    "    return res/norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class PoolHelper(object):\n",
    "    def __init__(self, num_samples, res, search):\n",
    "        self.num_samples = num_samples\n",
    "        self.res = res\n",
    "        self.search = search \n",
    "        \n",
    "    def __call__(self, noise):\n",
    "        return get_scores_with_noise(noise, self.num_samples, self.res, self.search)\n",
    "\n",
    "def get_scores_with_noise(noise, num_samples, res, search):\n",
    "    noise = noise/res\n",
    "\n",
    "    topic_scores_necs = []\n",
    "    topic_scores_ncbp = []\n",
    "    topic_scores_ncp = []\n",
    "    for topic in topics:\n",
    "        num_subtopics = len(sub_topics[topic])\n",
    "\n",
    "        all_r_documents = {}\n",
    "        all_r_inverted_index = {}\n",
    "        for sub_topic in sub_topics[topic]:\n",
    "            r_documents, r_inverted_index = get_search_engine(topic, sub_topic, qrels, direct_index, noise)\n",
    "            all_r_documents[sub_topic] = r_documents\n",
    "            all_r_inverted_index[sub_topic] = r_inverted_index\n",
    "\n",
    "        rel_table, irr_table, p_rel, _ = get_transitions_tables(num_subtopics, \n",
    "                                                                min(sub_topics[topic]), \n",
    "                                                                all_sequences[topic], \n",
    "                                                                10e-6)\n",
    "        scores_necs = []\n",
    "        scores_ncbp = []\n",
    "        scores_ncp = []\n",
    "        for _ in range(num_samples):\n",
    "            sg = SequenceGenerator(num_subtopics, min(sub_topics[topic]), rel_table, irr_table)\n",
    "            prob = 1.0\n",
    "            prev_sub_topic = 0\n",
    "            sequence = []\n",
    "            for m, (sub_topic, prob_action) in enumerate(sg):\n",
    "\n",
    "                if sub_topic != num_subtopics + 1 + min(sub_topics[topic]) - 1:\n",
    "                    query = ''\n",
    "                    if sub_topic in all_queries[topic] and len(all_queries[topic][sub_topic]) > 0: \n",
    "                        queries = all_queries[topic][sub_topic]\n",
    "                        query = queries[choice(range(len(queries)))]\n",
    "\n",
    "                    search.set_indices(all_r_inverted_index[sub_topic], all_r_documents[sub_topic])\n",
    "                    answer = search.search(query, \n",
    "                                           n=1, \n",
    "                                           retrievable_paragraphs=all_r_documents[sub_topic].keys())[0]\n",
    "\n",
    "                    if sub_topic in qrels_users[topic] and answer in qrels_users[topic][sub_topic] and \\\n",
    "                    np.random.uniform(0,1) < qrels_users[topic][sub_topic][answer]:\n",
    "                        sg.set_relevance(True)\n",
    "                        sequence.append((prev_sub_topic, answer, 'relevant', sub_topic, query))\n",
    "                    else:\n",
    "                        sg.set_relevance(False)\n",
    "                        sequence.append((prev_sub_topic, answer, 'irrelevant', sub_topic, query))\n",
    "                \n",
    "                prev_sub_topic = sub_topic\n",
    "                prob *= prob_action\n",
    "\n",
    "            scores_necs.append(necs(sequence, 0.85, 0.64))\n",
    "            scores_ncbp.append(ncbp(sequence, 0.79))\n",
    "            scores_ncp.append(ncp(sequence))\n",
    "\n",
    "        scores_necs = np.array(scores_necs)\n",
    "        topic_score_necs = np.mean(scores_necs)\n",
    "        topic_scores_necs.append((topic, topic_score_necs))\n",
    "        \n",
    "        scores_ncbp = np.array(scores_ncbp)\n",
    "        topic_score_ncbp = np.mean(scores_ncbp)\n",
    "        topic_scores_ncbp.append((topic, topic_score_ncbp))\n",
    "        \n",
    "        scores_ncp = np.array(scores_ncp)\n",
    "        topic_score_ncp = np.mean(scores_ncp)\n",
    "        topic_scores_ncp.append((topic, topic_score_ncp))\n",
    "\n",
    "    return noise, topic_scores_necs, topic_scores_ncbp, topic_scores_ncp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_all_evaluation_measures(pool_res):\n",
    "    ys_ncp = []\n",
    "    ys_ncbp = []\n",
    "    ys_necs = []\n",
    "    for noise, topic_scores_necs, topic_scores_ncbp, topic_scores_ncp in pool_res:\n",
    "        ys_necs.append(np.mean([tv[1] for tv in topic_scores_necs]))\n",
    "        ys_ncbp.append(np.mean([tv[1] for tv in topic_scores_ncbp]))\n",
    "        ys_ncp.append(np.mean([tv[1] for tv in topic_scores_ncp]))\n",
    "        \n",
    "    return {'necs': ys_necs, 'ncbp': ys_ncbp, 'ncp': ys_ncp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "res = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "res = 10\n",
    "\n",
    "search = Search(inverted_index=None, documents={}, pre_processor=pre_preocessor, scorer=TFIDF())\n",
    "\n",
    "noises = list(range(0, res+1))\n",
    "pool = Pool(len(noises))\n",
    "pool_res = list(pool.imap_unordered(PoolHelper(1, res, search), noises, chunksize=1))\n",
    "pool.terminate()\n",
    "\n",
    "tfidf_pool_res = pool_res\n",
    "all_evaluation_measures = get_all_evaluation_measures(pool_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "#model:  tf-idf\n",
      "measure\tnoise\tscore\n",
      "necs\t0.0\t0.6119747072327383\n",
      "necs\t0.1\t0.29527690287156877\n",
      "necs\t0.2\t0.28301227600338097\n",
      "necs\t0.3\t0.1515926992843726\n",
      "necs\t0.4\t0.13098098055944637\n",
      "necs\t0.5\t0.12276010008998307\n",
      "necs\t0.6\t0.12276010008998307\n",
      "necs\t0.7\t0.12276010008998307\n",
      "necs\t0.8\t0.12276010008998307\n",
      "necs\t0.9\t0.12231791842001992\n",
      "necs\t1.0\t0.07801578201685003\n",
      "ncbp\t0.0\t0.6531390520283302\n",
      "ncbp\t0.1\t0.31645723773506157\n",
      "ncbp\t0.2\t0.30903643109143386\n",
      "ncbp\t0.3\t0.17317889680229961\n",
      "ncbp\t0.4\t0.15366267702871345\n",
      "ncbp\t0.5\t0.13891612652839863\n",
      "ncbp\t0.6\t0.13891612652839863\n",
      "ncbp\t0.7\t0.13891612652839863\n",
      "ncbp\t0.8\t0.13891612652839863\n",
      "ncbp\t0.9\t0.13496668388800603\n",
      "ncbp\t1.0\t0.09775076737662501\n",
      "ncp\t0.0\t0.6606060606060606\n",
      "ncp\t0.1\t0.28484848484848485\n",
      "ncp\t0.2\t0.2996336996336996\n",
      "ncp\t0.3\t0.16450216450216448\n",
      "ncp\t0.4\t0.14177489177489175\n",
      "ncp\t0.5\t0.12878787878787878\n",
      "ncp\t0.6\t0.12878787878787878\n",
      "ncp\t0.7\t0.12878787878787878\n",
      "ncp\t0.8\t0.12878787878787878\n",
      "ncp\t0.9\t0.11363636363636363\n",
      "ncp\t1.0\t0.09848484848484848\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('#model: ', 'tf-idf')\n",
    "print('measure\\tnoise\\tscore')\n",
    "for m, l in all_evaluation_measures.items():\n",
    "    for n, i in enumerate(l):\n",
    "        print(m + '\\t' + str(n/res) + '\\t' + str(i))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D-LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "max_necs = 0\n",
    "max_pool_res = None\n",
    "\n",
    "for mu in tqdm(range(10 + 1)):\n",
    "    mu = (mu + 1) * 10\n",
    "    \n",
    "    search = Search(None, {}, pre_preocessor, scorer=DirichletSmoothingLM(mu))\n",
    "    \n",
    "    noises = list(range(0, res+1))\n",
    "    pool = Pool(32)\n",
    "    pool_res = list(pool.imap_unordered(get_scores_with_noise, noises, chunksize=1))\n",
    "    pool.terminate()\n",
    "    \n",
    "    cur_necs = max(get_all_evaluation_measures(pool_res)['necs'])\n",
    "    if max_necs < cur_necs:\n",
    "        max_necs = cur_necs\n",
    "        max_mu = mu\n",
    "        max_pool_res = pool_res\n",
    "\n",
    "d_lm_pool_res = max_pool_res\n",
    "d_lm_mu = max_mu\n",
    "get_all_evaluation_measures(max_pool_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74bfc42636c4e16933e0bff18200b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-105:\n",
      "Process ForkPoolWorker-104:\n",
      "Process ForkPoolWorker-99:\n",
      "Process ForkPoolWorker-102:\n",
      "Process ForkPoolWorker-100:\n",
      "Process ForkPoolWorker-113:\n",
      "Process ForkPoolWorker-115:\n",
      "Process ForkPoolWorker-117:\n",
      "Process ForkPoolWorker-114:\n",
      "Process ForkPoolWorker-120:\n",
      "Process ForkPoolWorker-109:\n",
      "Process ForkPoolWorker-126:\n",
      "Process ForkPoolWorker-119:\n",
      "Process ForkPoolWorker-122:\n",
      "Process ForkPoolWorker-112:\n",
      "Process ForkPoolWorker-118:\n",
      "Process ForkPoolWorker-111:\n",
      "Process ForkPoolWorker-123:\n",
      "Process ForkPoolWorker-101:\n",
      "Process ForkPoolWorker-124:\n",
      "Process ForkPoolWorker-110:\n",
      "Process ForkPoolWorker-108:\n",
      "Process ForkPoolWorker-97:\n",
      "Process ForkPoolWorker-98:\n",
      "Process ForkPoolWorker-127:\n",
      "Process ForkPoolWorker-125:\n",
      "Process ForkPoolWorker-116:\n",
      "Process ForkPoolWorker-128:\n",
      "Process ForkPoolWorker-121:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-107:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"<ipython-input-17-5934357920ba>\", line 13, in get_scores_with_noise\n",
      "    r_documents, r_inverted_index = get_search_engine(topic, sub_topic, qrels, direct_index, noise)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"<ipython-input-17-5934357920ba>\", line 13, in get_scores_with_noise\n",
      "    r_documents, r_inverted_index = get_search_engine(topic, sub_topic, qrels, direct_index, noise)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"<ipython-input-9-5e777cc9ce7e>\", line 37, in get_search_engine\n",
      "    inverted_index.create(selected_documents)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"<ipython-input-9-5e777cc9ce7e>\", line 37, in get_search_engine\n",
      "    inverted_index.create(selected_documents)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/exps/SIGDIAL/ConversationalSearchEvaluation/search_engine.py\", line 146, in create\n",
      "    self.index[term] += [(document_id, tf)]\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/alipani/exps/SIGDIAL/ConversationalSearchEvaluation/search_engine.py\", line 147, in create\n",
      "    self.cl += tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-17-5934357920ba>\", line 13, in get_scores_with_noise\n",
      "    r_documents, r_inverted_index = get_search_engine(topic, sub_topic, qrels, direct_index, noise)\n",
      "  File \"<ipython-input-9-5e777cc9ce7e>\", line 37, in get_search_engine\n",
      "    inverted_index.create(selected_documents)\n",
      "  File \"/home/alipani/exps/SIGDIAL/ConversationalSearchEvaluation/search_engine.py\", line 146, in create\n",
      "    self.index[term] += [(document_id, tf)]\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-106:\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-17-5934357920ba>\", line 13, in get_scores_with_noise\n",
      "    r_documents, r_inverted_index = get_search_engine(topic, sub_topic, qrels, direct_index, noise)\n",
      "  File \"<ipython-input-9-5e777cc9ce7e>\", line 37, in get_search_engine\n",
      "    inverted_index.create(selected_documents)\n",
      "  File \"/home/alipani/exps/SIGDIAL/ConversationalSearchEvaluation/search_engine.py\", line 146, in create\n",
      "    self.index[term] += [(document_id, tf)]\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-54238c3eb0c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnoises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpool_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_scores_with_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoises\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-103:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alipani/anaconda3/envs/ConversationalSearchEvaluation/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "max_necs = 0\n",
    "max_pool_res = None\n",
    "max_b = 0.0\n",
    "max_k1 = 0.0\n",
    "\n",
    "for k1 in tqdm(range(20 + 1)):\n",
    "    k1 = k1 / 10 + 0.5\n",
    "\n",
    "    for b in range(10 + 1):\n",
    "        b = b / 10\n",
    "\n",
    "        search = Search(None, {}, pre_preocessor, scorer=BM25(b, k1))\n",
    "\n",
    "        noises = list(range(0, res+1))\n",
    "        pool = Pool(32)\n",
    "        pool_res = list(pool.imap_unordered(get_scores_with_noise, noises, chunksize=1))\n",
    "        pool.terminate()\n",
    "\n",
    "        cur_necs = max(get_all_evaluation_measures(pool_res)['necs'])\n",
    "        if max_necs < cur_necs:\n",
    "            max_necs = cur_necs\n",
    "            max_pool_res = pool_res\n",
    "            max_b = b\n",
    "            max_k1 = k1\n",
    "\n",
    "bm25_pool_res = max_pool_res\n",
    "bm25_b = max_b\n",
    "bm25_k1 = max_k1\n",
    "get_all_evaluation_measures(max_pool_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}